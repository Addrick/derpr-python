# derpr todo:

- add module for voice chat functionality
- add throttle to discord so it will delay rather than spamming until discord refuses
- exclude dev commands from context in queries (emoji codes? threads? in-code filtering?)
- explore utilizing rag
    > RAG-tuned models can be found on HF. can chatgpt or other general models utilize this?
    > I think RAG is done as a function within the transformer logic so it's unclear if a gguf can be used
    > seems related to being able to run internal functions so that may be good to implement alongside
- explore storm (wiki generator)
- implement anthropic and google api calls since they are competitive models now and seem to be rated higher on coding tasks than gpt-4

# Features:
# TODO: integrate huggingface hub for easy changing of local model weights
# TODO: TIME based memory instead of message #s or 'start conversation' system
# TODO: make tiny gui for easier parameter tuning
# TODO: add multiple hyperparameter fields for personas to account for differences in models (ie openai_temp vs local_model_x_temp. Wonder if some kind of crude modifiers can work)
# TODO: create new TODOs via chat interface (dev command to write to this file? need to make .txt for security)
# TODO: Create chat channel in herp for error/console dumping; add try/except to message processors
# TODO: dev command to cancel a generation and dump partial reply #/api/extra/generate/check #/api/extra/abort
# TODO: have a 'default' model tag which uses whatever model is defined as default in config (for mass updating since most use 3.5t)
# TODO: add local model config list to util function, ability to specify config file on local model launch
# TODO: expand 'set model' such that it can spin up any given model in koboldcpp from a preconfigured list (adding hf transformers somehow would be sweet as well)
# TODO: command to toggle token and model display
# TODO: include context count in reply w/tokens
# TODO: consider making personas use server or channel specific configurations for context and other params

# TODO: Better persona management:
# change settings for all personas
# better save format?
# start/sleep
# don't resave all personas on each update
# print all personas w/info with one command
# record token usage
# ui to help modify personas or view info like messages as they are being generated


# TODO: try out various processing tricks like using LLM queries to evaluate the start/end of conversations or other lofty things
# TODO: modify: add option to locate name anywhere in message for reply rather than first word only?
# TODO: modify: make 'ignore other persona messages' a flag to allow for persona conversations (+commands to modify in-chat)
# TODO: print persona details cmd ('what personas' extension?)
# TODO: add temperature customizing commands
# TODO: add personal messages: currently break due to lack of channel or guild name (both?)
# TODO: add a persona prompt log - keep losing personas and wanting old versions back
# TODO: derpr persona should reset after some length of time or at least on restart.
# TODO: easier way to write gpt-3.5-turbo  (ie 'gpt3'==)
# TODO: new function to handle when derpr responds (include @derpr and every-message options)

# Bugfixes:
# TODO: developer commands end up in message history, usually don't want this
# TODO: all persona settings except prompt are lost UNLESS prompt is also changed. Need to add a method to all these updates to resave. Kind of like this now as I usually don't want permanent changes but still seems not ideal behavior
# TODO(BIG): filter history/context for dev commands so they don't pollute input (check each history line with preprocess()?)
# TODO: koboldcpp console messages are not pushed to the debug discord channel for some reason

LOCAL PERSONA MANAGEMENT:
- problem: local models (all models really) have different ideal temperature ranges, but variables are only saved on a persona level
- option: use different persona for different local models (problem: only one can be live at a time)
    > ie one named 'mixtral', 'mistral70b', etc
    > expand launch_kobold command to launch_<persona>, would need handler to prevent multiple instances (or check memory availability somehow)

- option: use normal temps associated with persona and just modify them each time (problem: will be a pain if multiple models are used with one persona)
    > easy to implement
    > still would support above functionality of creating multiple personas for each different model
    > implementing an expanded version of launch_kobold is still warranted and can be done separately

- option: make temperatures tied to specific models (problem: need to redo persona saving system)
    > create configuration for each model under each persona and default model values for the first time it was used x models as configurations
    > would probably want to upgrade the configuration system before implementing this
    > models update:
        + will need to expand model so each is an object with the necessary parameters
        + Models can no longer be dealt with entirely by name
        + update_models()
        + database of available models and their default values? save yaml in config for each persona?
    > can maybe use this to configure local models that use different parameters so that they are properly called via the api
    > example yaml: persona (name, prompt, context_limit, model (temperature, top_p, top_k, other model-specific parameters))